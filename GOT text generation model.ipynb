{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c389956e",
   "metadata": {},
   "source": [
    "# Game Of Thrones Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eebac7",
   "metadata": {},
   "source": [
    "## Importing Libraries and Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4470ebeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:36.735585Z",
     "start_time": "2022-06-10T10:03:28.953040Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feef0836",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:36.741026Z",
     "start_time": "2022-06-10T10:03:36.737853Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cf8951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:40.180808Z",
     "start_time": "2022-06-10T10:03:40.171883Z"
    }
   },
   "outputs": [],
   "source": [
    "# load document\n",
    "in_filename = 'GOT1.txt'\n",
    "doc = load_doc(in_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94daaa8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:40.789302Z",
     "start_time": "2022-06-10T10:03:40.781725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Game Of Thrones \\nBook One of A Song of Ice and Fire \\nBy George R. R. Martin \\nPROLOGUE \\n\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \\ndead.\" \\n\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \\nGared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \\n\"Dead is dead,\" he said. \"We have no business with the dead.\" \\n\"Are they dead?\" Royce asked softly. \"What proof have we?\" \\n\"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for me.\" \\nWill had known they would drag him into the quarrel sooner or later. He wished it had been later rather \\nthan sooner. \"My mother told me that dead men sing no songs,\" he put in. \\n\"My wet nurse said the same thing, Will,\" Royce replied. \"Never believe anything you hear at a woman\\'s \\ntit. There are things to be learned even from the dead.\" His voice echoed, too loud in the twilit forest. \\nPage 1\\n\\n\"We h'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d290b51",
   "metadata": {},
   "source": [
    "## EDA and Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f751e056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:41.445918Z",
     "start_time": "2022-06-10T10:03:41.401433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "296183\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))\n",
    "print(len(doc.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8980e6a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:41.648866Z",
     "start_time": "2022-06-10T10:03:41.645736Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_sample = doc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edb9a0e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:41.871644Z",
     "start_time": "2022-06-10T10:03:41.866670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Game Of Thrones \\nBook One of A Song of Ice and Fire \\nBy George R. R. Martin \\nPROLOGUE \\n\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \\ndead.\" \\n\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \\nGared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \\n\"Dead is dead,\" he said. \"We have no business with the dead.\" \\n\"Are they dead?\" Royce asked softly. \"What proof have we?\" \\n\"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for me.\" \\nWill had known they would drag him into the quarrel sooner or later. He wished it had been later rather \\nthan sooner. \"My mother told me that dead men sing no songs,\" he put in. \\n\"My wet nurse said the same thing, Will,\" Royce replied. \"Never believe anything you hear at a woman\\'s \\ntit. There are things to be learned even from the dead.\" His voice echoed, too loud in the twilit forest. \\nPage 1\\n\\n\"We h'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c3d0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:42.098690Z",
     "start_time": "2022-06-10T10:03:42.095260Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(corpus):\n",
    "    corpus = corpus.lower() #lowercase\n",
    "    corpus = re.sub(r\"[^\\w|\\d*]\", \" \", corpus) # remove punctuations\n",
    "    corpus = re.sub(r\"page\\s\\d\", \"\", corpus)\n",
    "    corpus = re.sub(r\"\\s{3}|\\s{2}\", \" \", corpus) # remove triple/double spaces\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a7eb42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:42.624933Z",
     "start_time": "2022-06-10T10:03:42.315572Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_corpus = clean_text(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f911d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:42.632804Z",
     "start_time": "2022-06-10T10:03:42.627811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a game of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead  do the dead frighten you ser waymar royce asked with just the hint of a smile gared did not rise to the bait he was an old man past fifty and he had seen the lordlings come and go  dead is dead he said we have no business with the dead  are they dead royce asked softly what proof have we  will saw them gared said if he says they are dead that s proof enough for me  will had known they would drag him into the quarrel sooner or later he wished it had been later rather than sooner my mother told me that dead men sing no songs he put in  my wet nurse said the same thing will royce replied never believe anything you hear at a woman s tit there are things to be learned even from the dead his voice echoed too loud in the twilit forest  we have a long ride before us gared pointed out eight days maybe nine and nig'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b588419f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:43.489690Z",
     "start_time": "2022-06-10T10:03:43.485120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523673"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9919f3e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:43.961784Z",
     "start_time": "2022-06-10T10:03:43.711084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD3CAYAAADyvkg2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAV/ElEQVR4nO3df5Dc9X3f8efdSugHPekYZ4mcCRhDkrdJalILLMkBBaWQKELN4NjJlFFtsN1gRORgTdKxXSOM1YgSU2CKHEc0BiIU8JgxNukYD0huYpuTTNBYxikk8LaBjJl26uak+iRFsn6dtn98v/qwnO8Xq5PvhJ6PmRvtfva93/18b7/7fe3n89k9dbVaLSRJAuie7A5IkqYOQ0GSVBgKkqTCUJAkFYaCJKmYNtkdOF5Hjx5tDQ76CaqJ0Gh04e9SU5nH6MSZPr2xE2gObT/pQ2FwsMXAwP7J7sbrQm/vbH+XmtI8RidOs9nz/eHanT6SJBWGgiSpMBQkSYWhIEkqDAVJUjHmp48iogF8FghgEHg/0AVsBFrAs8CqzDwaEdcC1wFHgHWZ+WhEzAIeAM4E9gLXZGZ/RCwC7qprt2Tm2vrxbgaW1+2rM3P7BO6vJGkU4xkp/BZAZl4MfAK4s/5Zk5mLqQLiyoiYB9wAXAwsBW6NiBnA9cAzde0mYE293buBFcAlwMKImB8R84FLgYXAVcBnJmQvJUnjMmYoZOZfAR+sr74J+L/AhcA36rbHgMuBBcC2zDyYmbuBF4ALqE76j7fXRsQcYEZmvpiZLWAzcFlduyUzW5n5MjAtIn7syxWSpBNjXF9ey8wjEXE/8NvA7wD/pj6ZQzUlNBeYA+xuu9tw7e1te4bUngscAHYNs43+kfrWaHTR2zt7PLuhMTQa3f4uNaV5jJ544/5Gc2ZeExEfBZ4CZrXd1AMMUJ3ke8ZoH6v20AjtIzqebzT3nnE606e51t6uu7sx2V2YEg4fOcrAD/dNdjc0hN9onjjNZs+w7eNZaH4v8LOZeSuwHzgKfCsilmTm14FlwNeA7cAtETETmAGcT7UIvQ24or59GdCXmXsi4lBEnAe8RLUGsZZqcfm2iLgd+FmgOzN3drzXY5g+rZtN233h68ddveD0ye6CNCnGM1L4EvAXEfEEMB1YDTwHfDYiTqsvP5yZgxGxHuijWqu4MTMPRMQG4P6I2Eo1ElhRb3cl8CDQoFpHeAogIvqAJ+ttrJqY3ZQkjUfXyf5/NB8+PNjqdDjZbPY4UtCwrl5wOv39eye7GxrC6aOJ02z27AAuGtruhLokqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKqaNdmNETAfuA84BZgDrgP8FfBn4Xl22ITMfiohrgeuAI8C6zHw0ImYBDwBnAnuBazKzPyIWAXfVtVsyc239eDcDy+v21Zm5fSJ3VpI0ulFDAXgPsCsz3xsRbwCeBv4TcGdm3nGsKCLmATcAFwEzga0R8VXgeuCZzPxkRFwFrAE+DNwNvBt4CfhKRMyvN3UpsBA4C/gi8PaJ2U1J0niMFQpfAB5uu34EuBCIiLiSarSwGlgAbMvMg8DBiHgBuAC4BLitvu9jwE0RMQeYkZkvUm1oM3AZcJBq1NACXo6IaRHRzMz+0TrYaHTR2zt73DssjZfH1dTTaHT7vJxgo4ZCZv4zQET0UIXDGqpppHsyc0dE3AjcDHwH2N12173AXGBOW3t7254htecCB4Bdw2xj1FAYHGwxMLB/tJIRNZs9Hd1Pp4ZOjyudOL29s31eJshI578xF5oj4izga8BfZubngEcyc0d98yPA26hO8u2P0AMMDGkfrm087ZKkn5BRQyEifhrYAnw0M++rmzdHxIL68mXADmA7sDgiZkbEXOB84FlgG3BFXbsM6MvMPcChiDgvIrqApUBfXbs0Iroj4mygOzN3TtieSpLGNNaawseBM6jWAm6q2/4Q+K8RcQj4AfDBzNwTEeupTu7dwI2ZeSAiNgD3R8RW4BCwot7GSuBBoEG1jvAUQET0AU/W21g1UTspSRqfrlarNdl9OC6HDw+2jmdNYdP2fRPcI70eXL3gdPr79052NzSEawoTp9ns2UH1idFX8ctrkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFdNGuzEipgP3AecAM4B1wD8AG4EW8CywKjOPRsS1wHXAEWBdZj4aEbOAB4Azgb3ANZnZHxGLgLvq2i2ZubZ+vJuB5XX76szcPrG7K0kazVgjhfcAuzJzMbAM+FPgTmBN3dYFXBkR84AbgIuBpcCtETEDuB54pq7dBKypt3s3sAK4BFgYEfMjYj5wKbAQuAr4zMTtpiRpPMYKhS8AN7VdPwJcCHyjvv4YcDmwANiWmQczczfwAnAB1Un/8fbaiJgDzMjMFzOzBWwGLqtrt2RmKzNfBqZFRPO491CSNG6jTh9l5j8DREQP8DDVO/3b65M5VFNCc4E5wO62uw7X3t62Z0jtucABYNcw2+gfrY+NRhe9vbNHK5E64nE19TQa3T4vJ9iooQAQEWcBjwB/lpmfi4jb2m7uAQaoTvI9Y7SPVXtohPZRDQ62GBjYP1bZsJrNnrGLdMrq9LjSidPbO9vnZYKMdP4bdfooIn4a2AJ8NDPvq5ufjogl9eVlQB+wHVgcETMjYi5wPtUi9DbgivbazNwDHIqI8yKii2oNoq+uXRoR3RFxNtCdmTs72ltJUkfGGil8HDgDuCkijq0tfBhYHxGnAc8BD2fmYESspzq5dwM3ZuaBiNgA3B8RW6lGAivqbawEHgQaVOsITwFERB/wZL2NVRO1k5Kk8elqtVpjV01hhw8Pto5n+mjT9n0T3CO9Hly94HT6+/dOdjc0hNNHE6fZ7NkBXDS03S+vSZIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqRi2niKImIh8KnMXBIR84EvA9+rb96QmQ9FxLXAdcARYF1mPhoRs4AHgDOBvcA1mdkfEYuAu+raLZm5tn6cm4HldfvqzNw+YXsqSRrTmKEQER8B3gvsq5vmA3dm5h1tNfOAG4CLgJnA1oj4KnA98ExmfjIirgLWAB8G7gbeDbwEfKUOGoBLgYXAWcAXgbcf9x5KksZtPNNHLwLvart+IbA8Ip6IiHsjogdYAGzLzIOZuRt4AbgAuAR4vL7fY8DlETEHmJGZL2ZmC9gMXFbXbsnMVma+DEyLiOZE7KQkaXzGHClk5hcj4py2pu3APZm5IyJuBG4GvgPsbqvZC8wF5rS1t7ftGVJ7LnAA2DXMNvpH61+j0UVv7+yxdkN6zTyupp5Go9vn5QQb15rCEI9k5sCxy8CngSeAnraaHmCA6uTfM0pbe/uhEdpHNTjYYmBg/2vagWOazZ6xi3TK6vS40onT2zvb52WCjHT+6+TTR5sjYkF9+TJgB9XoYXFEzIyIucD5wLPANuCKunYZ0JeZe4BDEXFeRHQBS4G+unZpRHRHxNlAd2bu7KB/kqQOdTJSuB7404g4BPwA+GBm7omI9VQn927gxsw8EBEbgPsjYivVSGBFvY2VwINAg2od4SmAiOgDnqy3seo49kuS1IGuVqs12X04LocPD7aOZ/po0/Z9YxfqlHP1gtPp79872d3QEE4fTZxms2cH1SdGX8Uvr0mSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkYtp4iiJiIfCpzFwSET8HbARawLPAqsw8GhHXAtcBR4B1mfloRMwCHgDOBPYC12Rmf0QsAu6qa7dk5tr6cW4GltftqzNz+wTuqyRpDGOOFCLiI8A9wMy66U5gTWYuBrqAKyNiHnADcDGwFLg1ImYA1wPP1LWbgDX1Nu4GVgCXAAsjYn5EzAcuBRYCVwGfmZhdlCSN13hGCi8C7wL+sr5+IfCN+vJjwG8Ag8C2zDwIHIyIF4ALqE76t7XV3hQRc4AZmfkiQERsBi4DDlKNGlrAyxExLSKamdk/WucajS56e2ePb2+l18DjauppNLp9Xk6wMUMhM78YEee0NXXVJ26opoTmAnOA3W01w7W3t+0ZUnsucADYNcw2Rg2FwcEWAwP7x9qNYTWbPR3dT6eGTo8rnTi9vbN9XibISOe/ca0pDHG07XIPMEB1ku8Zo32s2kMjtEuSfkI6+fTR0xGxpL68DOgDtgOLI2JmRMwFzqdahN4GXNFem5l7gEMRcV5EdFGtQfTVtUsjojsizga6M3NnpzsmSXrtOhkp/BHw2Yg4DXgOeDgzByNiPdXJvRu4MTMPRMQG4P6I2Eo1ElhRb2Ml8CDQoFpHeAogIvqAJ+ttrDqO/ZIkdaCr1WqNXTWFHT482DqeNYVN2/dNcI/0enD1gtPp79872d3QEK4pTJxms2cHcNHQdr+8JkkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBWGgiSpMBQkSYWhIEkqDAVJUjGt0ztGxNPA7vrqPwK3ABuBFvAssCozj0bEtcB1wBFgXWY+GhGzgAeAM4G9wDWZ2R8Ri4C76totmbm20/5Jkl67jkYKETETIDOX1D/vB+4E1mTmYqALuDIi5gE3ABcDS4FbI2IGcD3wTF27CVhTb/puYAVwCbAwIuZ3vmuSpNeq05HCLwOzI2JLvY2PAxcC36hvfwz4DWAQ2JaZB4GDEfECcAHVSf+2ttqbImIOMCMzXwSIiM3AZcC3O+yjJOk16jQU9gO3A/cAP091Yu/KzFZ9+15gLjCHV6aYRmpvb9szpPbcsTrSaHTR2zu7w92QRuZxNfU0Gt0+LydYp6HwXeCFOgS+GxG7qEYKx/QAA1Qn+Z4x2seqHdXgYIuBgf0d7AI0mz1jF+mU1elxpROnt3e2z8sEGen81+mnjz4A3AEQET9D9S5/S0QsqW9fBvQB24HFETEzIuYC51MtQm8Drmivzcw9wKGIOC8iuqjWIPo67J8kqQOdjhTuBTZGxFaqTxt9ANgJfDYiTgOeAx7OzMGIWE91cu8GbszMAxGxAbi/vv8hqsVlgJXAg0CD6tNHT3W6Y5Kk166r1WqNXTWFHT482Dqe6aNN2/dNcI/0enD1gtPp79872d3QEE4fTZxms2cHcNHQdr+8JkkqDAVJUmEoSJIKQ0GSVBgKkqTCUJAkFYaCJKkwFCRJhaEgSSoMBUlSYShIkgpDQZJUGAqSpMJQkCQVhoIkqTAUJEmFoSBJKgwFSVJhKEiSCkNBklQYCpKkwlCQJBXTJrsDkkb2ht4ZdE8/bbK7MaU0mz2T3YUp4+jhQ+waODih2zQUpCmse/pp8JU/nuxuaIrqXn4TMLGh4PSRJKkwFCRJhaEgSSqm3JpCRHQDfwb8MtVk2e9l5guT2ytJOjVMxZHCO4GZmfkO4GPAHZPbHUk6dUzFULgEeBwgM/8WuGhyuyNJp44pN30EzAF2t10fjIhpmXlkuOLp0xs7m82e73f6YFcvOL3Tu+p1bsp8Hn75TZPdA01hx3Gcvmm4xqkYCnuA9r3sHikQas0T3B9JOmVMxemjbcAVABGxCHhmcrsjSaeOqThSeAT49Yj4JtAFvH+S+yNJp4yuVqs12X2QJE0RU3H6SJI0SQwFSVJhKEiSiqm40KwhIuIO4EJgHjAbeAnoz8zfHab2rcAZmfnECNtaAqzMzKtOYH8/D9ydmV8/UY+hyTPcMRQRfwI8n5kbR7jPx4C/ycztP5FOdiAifhO4KjPfN9l9mUyGwkkgM/8IICLeB7wlMz82Svm7gR8Aw4aCNBky808muw8aH0PhJBUR04H7gPOABnAnsBV4H3AoIr4NnA2sovpoL8DvjLCtvwLWZea3IiKBj2XmIxGxheojwUuA1VR/oPB7wAeBfwd8gGoK8mbgLcDvAf8HOLPe7i8AG4HDwBHg6sz83xPzG9BUVI8iPgocAt4MPJSZt0TERuDzVMfo54AzgL8HfiUzL4iIr1ONPp6PiJXAvMz8ZET8AbACaAGfz8z1bY/1TuDyzPxQRPxHYFFmXhkR76E69j8H3AtMr+9/Q2b+XUR8H3geeA74b1Svo331zw/rbW+kem3NBG7PzIdOxO9rKnJN4eR1HbAzM38FuBxYR3XS3gjcWQ/TfwFYnplLgASWjrCtLwHLIuLNwAGq74nMpXpBHADWAv86My8BBurHBvhh3fYt4MPAIuBK4Nj/H/nrwI66f7dQnQj0+nXs8+1vohqxvgP4yJCa3weeyczFwCaqP2szrIj4ReDfUv09tEuAd0ZEtJVsBn61vrwYOCsipgG/RXVM3w6sz8xfpTo+761rzwJWZOZq4I+BT2Tm5cA368ftAX4NeBewjOpN1ynDUDh5nU89RZSZe4F/oHpn0+6fgPsj4i+AC6jeMQ3ny1Qn8N8EPgUsoHoxfBk4F/j7+jGoH/OX6stZ//uWuuZgZh4Gjs0b3wvspPoDhx+iGi3o5PcjYMaQtn9Rt0N10j+Smfva2o55M/XxkZnfpHrTMdSxke2/pAqYvwb+BngD8HPHijLzR8B3I+LtVKPRJ6lC4uzMfJ5Xv0a+QxUGUL2Z2lVf/iVeOV631bV7qY7XPwceGmZfX9cMhZPXc1Tvjo69s3kr8I/AUaC7fqe/FriKalrnR7zyYnuVzPwhsJ/qXdnjwMtU00Vfqrf5ixFx7C8HXgp8t758tP73pbpmVkQ0gLfV7VcCfZl5GfAFqmkFnfyeA94WEW8EiIiZVCfjb9e3j/aN2P8JXFzf761Uo1GowuGN9eX59b9JNcX0a/VodyM//mdvHgH+C/A1qpHDfwb+R1s/j71G/hXVWhu8ctxCNY30jvry2+vaNwIXZuZvA8uB2+oRyCnBUDh5/TnwhojYCnwdWJuZ/0Q1XfMhqhfWNqoXah9VKPzMKNv778DszPx/VC+uWZn5YmbupFoz+FpE/C3wU8CG9jtmZj/wCarh92NUc7NQTSvdEhF9wErg08e705p8mbkH+EPgK/Xx9wTw6XH+Z1j3APMi4glePbW0HvhMRGymnq7JzL+jGiVsjYhvAT8PDF2TepTqpL6FKhjmU72ZAfgPwB/Uj7UB+PfD9Of3gY9HxF8DC+u2H9R9fBr4KtWawikzyvXPXEiaFPUI4/nMPGey+6JXOFKQJBWOFCRJhSMFSVJhKEiSCkNBklQYCpKkwlCQJBX/H4ZrhPcylvA5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(x = [\"Total words\", \"Unique words\"], \n",
    "        height=[len(clean_corpus.split()), len(set(clean_corpus.split()))], \n",
    "        color=sns.color_palette('pastel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86dc329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T11:11:01.173424Z",
     "start_time": "2022-06-01T11:11:01.091284Z"
    }
   },
   "source": [
    "## Creating input and output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa8b78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:45.060624Z",
     "start_time": "2022-06-10T10:03:44.467357Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences_doc = []\n",
    "seq_len = 50\n",
    "l = seq_len + 1\n",
    "tokens = clean_corpus.split()\n",
    "\n",
    "for i in range(l, len(tokens)):\n",
    "    \n",
    "    seq = tokens[i-l:i]\n",
    "\n",
    "    line = ' '.join(seq)\n",
    "    sequences_doc.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a208aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:03:45.067359Z",
     "start_time": "2022-06-10T10:03:45.063166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_doc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b862d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9ac67b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:09.723014Z",
     "start_time": "2022-06-10T10:03:45.297308Z"
    }
   },
   "outputs": [],
   "source": [
    "# should take under 20 seconds\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequences_doc)\n",
    "sequences = tokenizer.texts_to_sequences(sequences_doc)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b803db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:09.731864Z",
     "start_time": "2022-06-10T10:04:09.725636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11471"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32c49ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:12.289217Z",
     "start_time": "2022-06-10T10:04:12.284054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1103, 5, 1781, 1309, 49, 5, 4, 1031, 5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e321907a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:20.232298Z",
     "start_time": "2022-06-10T10:04:20.227143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac23338c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:23.632637Z",
     "start_time": "2022-06-10T10:04:20.844156Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences=sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "113fdcf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:23.687351Z",
     "start_time": "2022-06-10T10:04:23.635014Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7153448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:24.623446Z",
     "start_time": "2022-06-10T10:04:23.690606Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1959522d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:24.710441Z",
     "start_time": "2022-06-10T10:04:24.668975Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model(vocab_size, seq_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b36614f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:04:25.866901Z",
     "start_time": "2022-06-10T10:04:25.349670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 50)            573550    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11471)             1158571   \n",
      "=================================================================\n",
      "Total params: 1,883,021\n",
      "Trainable params: 1,883,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "944b0261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:29:42.151036Z",
     "start_time": "2022-06-10T10:04:27.576159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "292/292 [==============================] - 321s 1s/step - loss: 6.8524 - accuracy: 0.0574\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 303s 1s/step - loss: 6.4599 - accuracy: 0.0603\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 319s 1s/step - loss: 6.2497 - accuracy: 0.0693\n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 311s 1s/step - loss: 6.0362 - accuracy: 0.0803\n",
      "Epoch 5/10\n",
      "251/292 [========================>.....] - ETA: 42s - loss: 5.8720 - accuracy: 0.0915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-97e692979e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97823ac",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0eb4ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:29:47.674635Z",
     "start_time": "2022-06-10T10:29:47.653428Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "    # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict(encoded, verbose=0)\n",
    "        yhat = np.argmax(yhat,axis=1)\n",
    "        print(yhat)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5519d7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T10:29:51.911575Z",
     "start_time": "2022-06-10T10:29:48.530765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you had not pointed it out from his vantage point atop the throne he could see men slipping out the door at the far end of the hall hares going to ground he supposed or rats off to nibble the queen s cheese he caught a glimpse of septa mordane\n",
      "\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n",
      "[54]\n",
      "[8]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the king was the'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = sequences_doc[np.random.randint(0,len(sequences_doc))]\n",
    "print(seed_text + '\\n')\n",
    "generate_seq(model, tokenizer, seq_length, seed_text, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0962d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = sequences_doc[np.random.randint(0,len(sequences_doc))]\n",
    "print(seed_text + '\\n')\n",
    "generate_seq(model, tokenizer, seq_length, seed_text, 50)[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191376cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"twitter_parsed_dataset.csv\")[\"Text\"][np.random.randint(0, len(pd.read_csv(\"twitter_parsed_dataset.csv\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97048234",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = sequences_doc[np.random.randint(0,len(sequences_doc))]\n",
    "print(seed_text + '\\n')\n",
    "generate_seq(model, tokenizer, seq_length, seed_text, 50)[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717585c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72543506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06f79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c886d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d0f4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec592a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
